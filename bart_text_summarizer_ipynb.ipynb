{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install transformers streamlit pyngrok --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMWYDZHSm9vD",
        "outputId": "3c76c512-3961-4564-f3ea-20262f0a2075"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hZqEGG1myDL",
        "outputId": "741930cc-6b77-46f8-b25f-1dccdbf8f243"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-08-25T19:47:10+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context deadline exceeded\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K\n",
            "changed 22 packages in 1s\n",
            "\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0KAuthtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Streamlit app URL: NgrokTunnel: \"https://29f00d55b6cb.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "# ===============================\n",
        "# Install required packages\n",
        "# ===============================\n",
        "!pip install -q transformers streamlit\n",
        "!npm install -g localtunnel\n",
        "\n",
        "# ===============================\n",
        "# Imports\n",
        "# ===============================\n",
        "import torch\n",
        "from pyngrok import ngrok\n",
        "import logging\n",
        "import re\n",
        "\n",
        "# ===============================\n",
        "# Set up logging\n",
        "# ===============================\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ===============================\n",
        "# Set your Ngrok authtoken here\n",
        "# ===============================\n",
        "NGROK_AUTHTOKEN = \"YOUR_NGROK_AUTHTOKEN_HERE\" ##  NGROK_AUTHTOKEN <<<<<<<<<<==================================================================\n",
        "!ngrok authtoken {NGROK_AUTHTOKEN}\n",
        "\n",
        "# ===============================\n",
        "# Model configuration\n",
        "# ===============================\n",
        "MODEL_NAME = \"facebook/bart-large-cnn\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ===============================\n",
        "# Streamlit app code\n",
        "# ===============================\n",
        "streamlit_code = f\"\"\"\n",
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import logging, re\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "MODEL_NAME = \"{MODEL_NAME}\"\n",
        "device = \"{device}\"\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Move model to GPU if available\n",
        "if device == \"cuda\":\n",
        "    model = model.to(device)\n",
        "\n",
        "# Clean input text\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\\\s+', ' ', text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "# Summarization function\n",
        "def summarize_text(text, max_input_len=1024, max_summary_len=150, min_summary_len=30):\n",
        "    text = clean_text(text)\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_input_len).to(device)\n",
        "    summary_ids = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_length=max_summary_len,\n",
        "        min_length=min_summary_len,\n",
        "        length_penalty=1.0,\n",
        "        num_beams=8,\n",
        "        no_repeat_ngram_size=3,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "# Streamlit interface\n",
        "st.title(\"Abstractive Text Summarizer (BART)\")\n",
        "st.write(\"Enter the text you want to summarize:\")\n",
        "\n",
        "user_input = st.text_area(\"Input text here:\", height=300)\n",
        "\n",
        "if st.button(\"Generate Summary\"):\n",
        "    if not user_input.strip():\n",
        "        st.warning(\"Please enter some text.\")\n",
        "    else:\n",
        "        with st.spinner(\"Generating summary...\"):\n",
        "            summary = summarize_text(user_input)\n",
        "            if len(summary.split()) < 10:\n",
        "                st.error(\"Generated summary is too short. Try a longer input.\")\n",
        "                logger.warning(\"Short summary detected\")\n",
        "            else:\n",
        "                st.subheader(\"Summary:\")\n",
        "                st.write(summary)\n",
        "                logger.info(\"Summary displayed successfully\")\n",
        "\"\"\"\n",
        "\n",
        "# ===============================\n",
        "# Save Streamlit app to file\n",
        "# ===============================\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(streamlit_code)\n",
        "\n",
        "# ===============================\n",
        "# Expose the app via Ngrok\n",
        "# ===============================\n",
        "public_url = ngrok.connect(addr=8501, proto=\"http\")\n",
        "print(f\"Streamlit app URL: {public_url}\")\n",
        "\n",
        "# ===============================\n",
        "# Run Streamlit app\n",
        "# ===============================\n",
        "get_ipython().system_raw(\"streamlit run app.py &\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1OcupzQ9m2Cu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}